# In[1]:

import os
import time
import sys
current = os.getcwd()
sys.path.append(os.path.join(current,'/home/user/Downloads/shap-master/'))
import shap
sys.path.remove(os.path.join(current,'/home/user/Downloads/shap-master/'))
os.chdir(current)
import yaml
import numpy as np
import pandas as pd
from src.util import ExeDataset, write_pred
from src.model import MalConv
from torch.utils.data import DataLoader
import torch.nn as nn
import torch.optim as optim
from torch.autograd import Variable
import time
import torch



# In[2]:
#sys.path.remove(os.path.join(os.getcwd(),'/home/user/Downloads/shap-master/')

# Load config file for experiment
current = os.getcwd()

config_path = '/home/user/Desktop/Explainability/GradDesc/config/example.yaml' #needs to modify to point to a new list of valid label
seed = int(123)
conf = yaml.load(open(config_path, 'r'), Loader = yaml.SafeLoader)

use_gpu = conf['use_gpu']
use_cpu = conf['use_cpu']
exp_name = conf['exp_name'] + '_sd_' + str(seed)

valid_data_path = conf['valid_data_path']
valid_label_path = conf['valid_label_path']

checkpoint_dir = conf['checkpoint_dir']
chkpt_acc_path = checkpoint_dir + exp_name + '.model'

val_label_table = pd.read_csv(valid_label_path, header=None, index_col=0)

val_label_table.index = val_label_table.index.str.upper()
val_label_table = val_label_table.rename(columns={1: 'ground_truth'})


# In[3]:


val_table = val_label_table.groupby(level=0).last()
#del val_label_table

validloader = DataLoader(ExeDataset(list(val_table.index), valid_data_path, list(val_table.ground_truth)),
                         batch_size=1, shuffle=False, num_workers=use_cpu)

malconv = torch.load('checkpoint/example_sd_123.model', map_location=torch.device('cpu'))

print("Loading MalConv model successful")

history = {}
history['val_loss'] = []
history['val_acc'] = []
history['val_pred'] = []
bce_loss = nn.BCEWithLogitsLoss()
total=0
evade = 0
changes=[]
temp_df = pd.DataFrame(columns=['exe_input'])
tensor_list = []


# In[4]:

for _, val_batch_data in enumerate(validloader):
    # total+=1
    # print(total)
    cur_batch_size = val_batch_data[0].size(0)
    #print("cur batch size:", cur_batch_size)

    exe_input = val_batch_data[0].cuda() if use_gpu else val_batch_data[0]

    data = exe_input[0].cpu().numpy()

    length = data[-1]
  
    data = data[:length]
    if length>2000000:
        continue

    # array_0 = np.full(2000000,0)
    # array_1 = np.full(2000000,256)
    # array_random = np.random.randint(0, 256, 2000000)

    data = np.concatenate([data, np.random.randint(0, 256, 2000000 - length)])

    init_prob = 0
 
    label = val_batch_data[1].cuda() if use_gpu else val_batch_data[1]
 
    label = Variable(label.float(), requires_grad=False)

    label = Variable(torch.from_numpy(np.array([[0]])).float(), requires_grad=False)

    embed = malconv.embed
    sigmoid = nn.Sigmoid()
    count_j = 0
    t=0

    exe_input = torch.from_numpy(np.array([data]))
    exe_input = Variable(exe_input.long(), requires_grad=False)

    exe_input = exe_input.to(dtype = torch.float32)
    # pred = malconv(exe_input)
    # prob = sigmoid(pred).cpu().data.numpy()[0][0]

    tensor_list.append(exe_input)
    total += 1
    if total>13:
        break
    if total%10==0:
        print(total)


#print(tensor_list[0:1])
background = torch.stack(tensor_list[0:10], dim = 0)
#background.shape
#explainer = shap.DeepExplainer(malconv, background)

#tensor_list[0:1][0].size()
background = background.squeeze(1)


#Shap model taking malconv and background data as input
 
explainer = shap.GradientExplainer(malconv.sigmoid, background)

#explainer = shap.GradientExplainer(malconv, background)


test_tensor = torch.stack(tensor_list[10:11],dim=0)
test_tensor = test_tensor.squeeze(1)

#test_tensor.shape
shap_values = explainer.shap_values(test_tensor,nsamples = 200)
np.savetxt('myfilesave.txt',shap_values[0], delimiter='\t')


# np.savetxt('myfilesave.txt',shap_values[0], delimiter='\t')
# print(np.sum(shap_values[0]))





