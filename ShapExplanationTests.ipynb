{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab67242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "current = os.getcwd()\n",
    "sys.path.append(os.path.join(current,'/home/user/Downloads/shap-master/'))\n",
    "import shap\n",
    "sys.path.remove(os.path.join(current,'/home/user/Downloads/shap-master/'))\n",
    "os.chdir(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622fec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.int32)\n",
    "        self.embed_x = self.embed(x)\n",
    "        x = torch.transpose(self.embed_x, -1, -2)\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        x = cnn_value * gating_weight\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "  \n",
    "#     def forward(self, x):\n",
    "#         x = x.to(dtype=torch.int32)\n",
    "#         self.embed_x = self.embed(x)\n",
    "#         self.embed_x.requires_grad = True\n",
    "#         x = torch.transpose(self.embed_x, -1, -2)\n",
    "#         cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "#         gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "#         x = cnn_value * gating_weight\n",
    "#         x = self.pooling(x)\n",
    "#         x = x.view(-1, 128)\n",
    "#         x = self.fc_1(x)\n",
    "#         x = self.fc_2(x)\n",
    "#         x = self.sigmoid(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe6bbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the MalConv model\n",
    "malconv_model = MalConv()\n",
    "malconv_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce78f3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3cf58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.GradientExplainer(malconv_model, input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd94975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_var = torch.autograd.Variable(input_data, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75086bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = malconv_model(input_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44c3b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_np = torch.autograd.grad(output, input_var, allow_unused=True)[0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c5f32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_gradients(module, grad_input, grad_output):\n",
    "    gradients.append(grad_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f366c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "malconv_model.fc_2.register_backward_hook(capture_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db7aa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = malconv_model(input_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c31767",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a19024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_np = input_var.grad.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52a72e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_tensor = torch.tensor(grads_np, dtype=torch.float32, device=input_data.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5930e2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values, indexes = explainer.shap_values(grads_tensor, ranked_outputs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eec745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import shap\n",
    "\n",
    "# Define the MalConv model\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.int32)\n",
    "        self.embed_x = self.embed(x)\n",
    "        x = torch.transpose(self.embed_x, -1, -2)\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        x = cnn_value * gating_weight\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the MalConv model\n",
    "malconv_model = MalConv()\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "malconv_model.eval()\n",
    "\n",
    "# Define the input data (replace this with your actual input data)\n",
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.float32)  # Example: single sample of length 2000000\n",
    "\n",
    "# Wrap the input in a torch.autograd.Variable for gradient computation\n",
    "input_var = torch.autograd.Variable(input_data, requires_grad=True)\n",
    "\n",
    "# Forward pass to get the model output\n",
    "output = malconv_model(input_var)\n",
    "\n",
    "# Print intermediate results\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Output values:\", output)\n",
    "\n",
    "# Backward pass to compute gradients\n",
    "grads = torch.autograd.grad(output, input_var, allow_unused=True)[0]\n",
    "\n",
    "# Print intermediate results\n",
    "print(\"Gradients:\", grads)\n",
    "\n",
    "# Check if gradients are not None before trying to access .detach().numpy()\n",
    "if grads is not None:\n",
    "    grads_np = grads.detach().numpy()\n",
    "    # Convert the numpy array to a PyTorch tensor with the appropriate device\n",
    "    grads_tensor = torch.tensor(grads_np, dtype=torch.float32, device=input_data.device)\n",
    "    print(\"Gradients tensor shape:\", grads_tensor.shape)\n",
    "\n",
    "    # Initialize the SHAP GradientExplainer with the MalConv model\n",
    "    explainer = shap.GradientExplainer(malconv_model, input_data)\n",
    "\n",
    "    # Use the manually computed gradients with shap_values method\n",
    "    shap_values, indexes = explainer.shap_values(grads_tensor, ranked_outputs=1)\n",
    "\n",
    "    # Print the SHAP values\n",
    "    print(\"SHAP values:\", shap_values)\n",
    "else:\n",
    "    print(\"Gradients are None.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5488d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import shap\n",
    "\n",
    "# Define the MalConv model\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.int32)\n",
    "        self.embed_x = self.embed(x)\n",
    "        self.embed_x = self.embed_x.detach()  # Detach to allow gradients through embedding\n",
    "        self.embed_x.requires_grad = True  # Set requires_grad explicitly\n",
    "        x = torch.transpose(self.embed_x, -1, -2)\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        x = cnn_value * gating_weight\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the MalConv model\n",
    "malconv_model = MalConv()\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "malconv_model.eval()\n",
    "\n",
    "# Define the input data (replace this with your actual input data)\n",
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.float32)  # Example: single sample of length 2000000\n",
    "\n",
    "# Wrap the input in a torch.autograd.Variable for gradient computation\n",
    "input_var = torch.autograd.Variable(input_data, requires_grad=True)\n",
    "\n",
    "# Forward pass to get the model output\n",
    "output = malconv_model(input_var)\n",
    "\n",
    "# Print intermediate results\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Output values:\", output)\n",
    "\n",
    "# Backward pass to compute gradients\n",
    "grads = torch.autograd.grad(output, input_var, allow_unused=True)[0]\n",
    "\n",
    "# Print intermediate results\n",
    "print(\"Gradients:\", grads)\n",
    "\n",
    "# Check if gradients are not None before trying to access .detach().numpy()\n",
    "if grads is not None:\n",
    "    grads_np = grads.detach().numpy()\n",
    "    # Convert the numpy array to a PyTorch tensor with the appropriate device\n",
    "    grads_tensor = torch.tensor(grads_np, dtype=torch.float32, device=input_data.device)\n",
    "    print(\"Gradients tensor shape:\", grads_tensor.shape)\n",
    "\n",
    "    # Initialize the SHAP GradientExplainer with the MalConv model\n",
    "    explainer = shap.GradientExplainer(malconv_model, input_data)\n",
    "\n",
    "    # Use the manually computed gradients with shap_values method\n",
    "    shap_values, indexes = explainer.shap_values(grads_tensor, ranked_outputs=1)\n",
    "\n",
    "    # Print the SHAP values\n",
    "    print(\"SHAP values:\", shap_values)\n",
    "else:\n",
    "    print(\"Gradients are None.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d29fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import shap\n",
    "\n",
    "# Define the MalConv model\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.int32)\n",
    "        self.embed_x = self.embed(x)\n",
    "        self.embed_x = self.embed_x.detach()  # Detach to allow gradients through embedding\n",
    "        self.embed_x.requires_grad = True  # Set requires_grad explicitly\n",
    "        x = torch.transpose(self.embed_x, -1, -2)\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        x = cnn_value * gating_weight\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the MalConv model\n",
    "malconv_model = MalConv()\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "malconv_model.eval()\n",
    "\n",
    "# Define the input data (replace this with your actual input data)\n",
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.long)  # Example: single sample of length 2000000\n",
    "\n",
    "# Wrap the input in a torch.autograd.Variable for gradient computation\n",
    "input_var = torch.autograd.Variable(input_data, requires_grad=True)\n",
    "\n",
    "# Forward pass to get the model output\n",
    "output = malconv_model(input_var)\n",
    "\n",
    "# Print intermediate results\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Output values:\", output)\n",
    "\n",
    "# Backward pass to compute gradients\n",
    "grads = torch.autograd.grad(output, input_var, allow_unused=True)[0]\n",
    "\n",
    "# Print intermediate results\n",
    "print(\"Gradients:\", grads)\n",
    "\n",
    "# Check if gradients are not None before trying to access .detach().numpy()\n",
    "if grads is not None:\n",
    "    grads_np = grads.detach().numpy()\n",
    "    # Convert the numpy array to a PyTorch tensor with the appropriate device\n",
    "    grads_tensor = torch.tensor(grads_np, dtype=torch.float32, device=input_data.device)\n",
    "    print(\"Gradients tensor shape:\", grads_tensor.shape)\n",
    "\n",
    "    # Initialize the SHAP GradientExplainer with the MalConv model\n",
    "    explainer = shap.GradientExplainer(malconv_model, input_data)\n",
    "\n",
    "    # Use the manually computed gradients with shap_values method\n",
    "    shap_values, indexes = explainer.shap_values(grads_tensor, ranked_outputs=1)\n",
    "\n",
    "    # Print the SHAP values\n",
    "    print(\"SHAP values:\", shap_values)\n",
    "else:\n",
    "    print(\"Gradients are None.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5398e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import shap\n",
    "\n",
    "# Define the MalConv model\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.int32)\n",
    "        self.embed_x = self.embed(x)\n",
    "        self.embed_x = self.embed_x.detach()  # Detach to allow gradients through embedding\n",
    "        self.embed_x.requires_grad = True  # Set requires_grad explicitly\n",
    "        x = torch.transpose(self.embed_x, -1, -2)\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        x = cnn_value * gating_weight\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the MalConv model\n",
    "malconv_model = MalConv()\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "malconv_model.eval()\n",
    "\n",
    "# Define the input data (replace this with your actual input data)\n",
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.float32)  # Example: single sample of length 2000000\n",
    "\n",
    "# Wrap the input in a torch.autograd.Variable for gradient computation\n",
    "input_var = torch.autograd.Variable(input_data, requires_grad=True)\n",
    "\n",
    "# Forward pass to get the model output\n",
    "output = malconv_model(input_var)\n",
    "\n",
    "# Print intermediate results\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Output values:\", output)\n",
    "\n",
    "# Backward pass to compute gradients\n",
    "grads = torch.autograd.grad(output, input_var, allow_unused=True)[0]\n",
    "\n",
    "# Print intermediate results\n",
    "print(\"Gradients:\", grads)\n",
    "\n",
    "# Check if gradients are not None before trying to access .detach().numpy()\n",
    "if grads is not None:\n",
    "    grads_np = grads.detach().numpy()\n",
    "    # Convert the numpy array to a PyTorch tensor with the appropriate device\n",
    "    grads_tensor = torch.tensor(grads_np, dtype=torch.float32, device=input_data.device)\n",
    "    print(\"Gradients tensor shape:\", grads_tensor.shape)\n",
    "\n",
    "    # Initialize the SHAP GradientExplainer with the MalConv model\n",
    "    explainer = shap.GradientExplainer(malconv_model, input_data)\n",
    "\n",
    "    # Use the manually computed gradients with shap_values method\n",
    "    shap_values, indexes = explainer.shap_values(grads_tensor, ranked_outputs=1)\n",
    "\n",
    "    # Print the SHAP values\n",
    "    print(\"SHAP values:\", shap_values)\n",
    "else:\n",
    "    print(\"Gradients are None.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db73f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import shap\n",
    "\n",
    "# Define the MalConv model\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.int32)\n",
    "        self.embed_x = self.embed(x)\n",
    "        self.embed_x = self.embed_x.detach()  # Detach to allow gradients through embedding\n",
    "        self.embed_x.requires_grad = True  # Set requires_grad explicitly\n",
    "        x = torch.transpose(self.embed_x, -1, -2)\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        x = cnn_value * gating_weight\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the MalConv model\n",
    "malconv_model = MalConv()\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "malconv_model.eval()\n",
    "\n",
    "# Define the input data (replace this with your actual input data)\n",
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.float32)  # Example: single sample of length 2000000\n",
    "\n",
    "# Wrap the input in a torch.autograd.Variable for gradient computation\n",
    "input_var = torch.autograd.Variable(input_data, requires_grad=True)\n",
    "\n",
    "# Forward pass to get the model output\n",
    "output = malconv_model(input_var)\n",
    "\n",
    "# Manually compute gradients for the embedding layer\n",
    "embedding_gradients = torch.autograd.grad(output, malconv_model.embed.weight, allow_unused=True)[0]\n",
    "\n",
    "# Apply gradients to the embedded input\n",
    "embedded_input_gradients = torch.nn.functional.embedding(input_data, embedding_gradients)\n",
    "\n",
    "# Print intermediate results\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Output values:\", output)\n",
    "\n",
    "# Print the embedded input gradients\n",
    "print(\"Embedded input gradients shape:\", embedded_input_gradients.shape)\n",
    "print(\"Embedded input gradients:\", embedded_input_gradients)\n",
    "\n",
    "# Initialize the SHAP GradientExplainer with the MalConv model\n",
    "explainer = shap.GradientExplainer(malconv_model, input_data)\n",
    "\n",
    "# Use the manually computed gradients with shap_values method\n",
    "shap_values, indexes = explainer.shap_values(embedded_input_gradients, ranked_outputs=1)\n",
    "\n",
    "# Print the SHAP values\n",
    "print(\"SHAP values:\", shap_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdd07ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import shap\n",
    "\n",
    "# Define the MalConv model\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # Register a hook to intercept gradients for the Embedding layer\n",
    "        self.embed.register_backward_hook(self._capture_embedding_gradients)\n",
    "\n",
    "        # Placeholder to store gradients for the Embedding layer\n",
    "        self.embedding_gradients = None\n",
    "\n",
    "    def _capture_embedding_gradients(self, module, grad_input, grad_output):\n",
    "        # Store the gradients for the Embedding layer\n",
    "        self.embedding_gradients = grad_input[0]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.int32)\n",
    "        self.embed_x = self.embed(x)\n",
    "        self.embed_x = self.embed_x.detach()  # Detach to allow gradients through embedding\n",
    "        self.embed_x.requires_grad = True  # Set requires_grad explicitly\n",
    "        x = torch.transpose(self.embed_x, -1, -2)\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        x = cnn_value * gating_weight\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the MalConv model\n",
    "malconv_model = MalConv()\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "malconv_model.eval()\n",
    "\n",
    "# Define the input data (replace this with your actual input data)\n",
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.float32)  # Example: single sample of length 2000000\n",
    "\n",
    "# Wrap the input in a torch.autograd.Variable for gradient computation\n",
    "input_var = torch.autograd.Variable(input_data, requires_grad=True)\n",
    "\n",
    "# Forward pass to get the model output\n",
    "output = malconv_model(input_var)\n",
    "\n",
    "# Backward pass to compute gradients\n",
    "output.backward()\n",
    "\n",
    "# Use the captured gradients for the Embedding layer\n",
    "embedding_gradients = malconv_model.embedding_gradients\n",
    "\n",
    "# Apply gradients to the embedded input\n",
    "embedded_input_gradients = torch.nn.functional.embedding(input_data, embedding_gradients)\n",
    "\n",
    "# Print intermediate results\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Output values:\", output)\n",
    "\n",
    "# Print the embedded input gradients\n",
    "print(\"Embedded input gradients shape:\", embedded_input_gradients.shape)\n",
    "print(\"Embedded input gradients:\", embedded_input_gradients)\n",
    "\n",
    "# Initialize the SHAP GradientExplainer with the MalConv model\n",
    "explainer = shap.GradientExplainer(malconv_model, input_data)\n",
    "\n",
    "# Use the manually computed gradients with shap_values method\n",
    "shap_values, indexes = explainer.shap_values(embedded_input_gradients, ranked_outputs=1)\n",
    "\n",
    "# Print the SHAP values\n",
    "print(\"SHAP values:\", shap_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb7c426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import shap\n",
    "\n",
    "# Define the MalConv model\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.int32)\n",
    "        self.embed_x = self.embed(x)\n",
    "        self.embed_x = self.embed_x.detach()  # Detach to allow gradients through embedding\n",
    "        self.embed_x.requires_grad = True  # Set requires_grad explicitly\n",
    "        x = torch.transpose(self.embed_x, -1, -2)\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        x = cnn_value * gating_weight\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the MalConv model\n",
    "malconv_model = MalConv()\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "malconv_model.eval()\n",
    "\n",
    "# Define the input data (replace this with your actual input data)\n",
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.float32)  # Example: single sample of length 2000000\n",
    "\n",
    "# Wrap the input in a torch.autograd.Variable for gradient computation\n",
    "input_var = torch.autograd.Variable(input_data, requires_grad=True)\n",
    "\n",
    "# Forward pass to get the model output\n",
    "output = malconv_model(input_var)\n",
    "\n",
    "# Backward pass to compute gradients\n",
    "output.backward()\n",
    "\n",
    "# Use the embedding layer's weights for SHAP values computation\n",
    "embedding_weights = malconv_model.embed.weight\n",
    "shap_values = shap_values = shap.GradientExplainer(malconv_model, input_data).shap_values(embedding_weights, ranked_outputs=1)\n",
    "\n",
    "# Print the SHAP values\n",
    "print(\"SHAP values:\", shap_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005107e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import shap\n",
    "\n",
    "# Define the MalConv model\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.int32)\n",
    "        self.embed_x = self.embed(x)\n",
    "        self.embed_x = self.embed_x.detach()  # Detach to allow gradients through embedding\n",
    "        self.embed_x.requires_grad = True  # Set requires_grad explicitly\n",
    "        x = torch.transpose(self.embed_x, -1, -2)\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        x = cnn_value * gating_weight\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the MalConv model\n",
    "malconv_model = MalConv()\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "malconv_model.eval()\n",
    "\n",
    "# Define the input data (replace this with your actual input data)\n",
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.float32)  # Example: single sample of length 2000000\n",
    "\n",
    "# Wrap the input in a torch.autograd.Variable for gradient computation\n",
    "input_var = torch.autograd.Variable(input_data, requires_grad=True)\n",
    "\n",
    "# Forward pass to get the model output\n",
    "output = malconv_model(input_var)\n",
    "\n",
    "# Backward pass to compute gradients\n",
    "output.backward()\n",
    "\n",
    "# Use the embedding layer's weights for SHAP values computation\n",
    "embedding_weights = malconv_model.embed.weight\n",
    "shap_values = shap.GradientExplainer(malconv_model, input_data).shap_values(embedding_weights, ranked_outputs=1)\n",
    "\n",
    "# Print the SHAP values\n",
    "print(\"SHAP values:\", shap_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bc6995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import shap\n",
    "\n",
    "# Define the MalConv model\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.int32)\n",
    "        self.embed_x = self.embed(x)\n",
    "        self.embed_x = self.embed_x.detach()  # Detach to allow gradients through embedding\n",
    "        self.embed_x.requires_grad = True  # Set requires_grad explicitly\n",
    "        x = torch.transpose(self.embed_x, -1, -2)\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        x = cnn_value * gating_weight\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the MalConv model\n",
    "malconv_model = MalConv()\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "malconv_model.eval()\n",
    "\n",
    "# Define the input data (replace this with your actual input data)\n",
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.float32)  # Example: single sample of length 2000000\n",
    "\n",
    "# Wrap the input in a torch.autograd.Variable for gradient computation\n",
    "input_var = torch.autograd.Variable(input_data, requires_grad=True)\n",
    "\n",
    "# Forward pass to get the model output\n",
    "output = malconv_model(input_var)\n",
    "\n",
    "# Backward pass to compute gradients\n",
    "output.backward()\n",
    "\n",
    "# Use the original input data for SHAP values computation\n",
    "shap_values = shap.GradientExplainer(malconv_model, input_data).shap_values(input_data, ranked_outputs=1)\n",
    "\n",
    "# Print the SHAP values\n",
    "print(\"SHAP values:\", shap_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232cbb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import shap\n",
    "\n",
    "# Define the MalConv model\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.int32)\n",
    "        self.embed_x = self.embed(x)\n",
    "        self.embed_x = self.embed_x.detach()  # Detach to allow gradients through embedding\n",
    "        self.embed_x.requires_grad = True  # Set requires_grad explicitly\n",
    "        x = torch.transpose(self.embed_x, -1, -2)\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        x = cnn_value * gating_weight\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the MalConv model\n",
    "malconv_model = MalConv()\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "malconv_model.eval()\n",
    "\n",
    "# Define the input data (replace this with your actual input data)\n",
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.float32)  # Example: single sample of length 2000000\n",
    "\n",
    "# Wrap the input in a torch.autograd.Variable for gradient computation\n",
    "input_var = torch.autograd.Variable(input_data, requires_grad=True)\n",
    "\n",
    "# Forward pass to get the model output\n",
    "output = malconv_model(input_var)\n",
    "\n",
    "# Backward pass to compute gradients\n",
    "output.backward()\n",
    "\n",
    "# Extract gradients from the embedded input\n",
    "embedding_gradients = input_var.grad.data\n",
    "\n",
    "# Use the GradientExplainer for SHAP values computation\n",
    "explainer = shap.GradientExplainer(malconv_model, input_data)\n",
    "shap_values = explainer.shap_values(input_data, ranked_outputs=1)\n",
    "\n",
    "# Print the SHAP values\n",
    "print(\"SHAP values:\", shap_values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f13fee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import shap\n",
    "\n",
    "# Define the MalConv model\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.int32)\n",
    "        self.embed_x = self.embed(x)\n",
    "        self.embed_x = self.embed_x.detach()  # Detach to allow gradients through embedding\n",
    "        self.embed_x.requires_grad = True  # Set requires_grad explicitly\n",
    "        x = torch.transpose(self.embed_x, -1, -2)\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        x = cnn_value * gating_weight\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the MalConv model\n",
    "malconv_model = MalConv()\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "malconv_model.eval()\n",
    "\n",
    "# Define the input data (replace this with your actual input data)\n",
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.float32)  # Example: single sample of length 2000000\n",
    "\n",
    "# Wrap the input in a torch.autograd.Variable for gradient computation\n",
    "input_var = torch.autograd.Variable(input_data, requires_grad=True)\n",
    "\n",
    "# Forward pass to get the model output\n",
    "output = malconv_model(input_var)\n",
    "\n",
    "# Backward pass to compute gradients\n",
    "output.backward()\n",
    "\n",
    "# Extract gradients from the embedded input\n",
    "embedding_gradients = input_var.grad\n",
    "\n",
    "# Use the GradientExplainer for SHAP values computation\n",
    "explainer = shap.GradientExplainer(malconv_model, input_data)\n",
    "shap_values = explainer.shap_values(input_data, ranked_outputs=1)\n",
    "\n",
    "# Print the SHAP values\n",
    "print(\"SHAP values:\", shap_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba55f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "# Define the MalConv model\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.int32)\n",
    "        self.embed_x = self.embed(x)\n",
    "        self.embed_x = self.embed_x.detach()  # Detach to allow gradients through embedding\n",
    "        self.embed_x.requires_grad = True  # Set requires_grad explicitly\n",
    "        x = torch.transpose(self.embed_x, -1, -2)\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        x = cnn_value * gating_weight\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the MalConv model\n",
    "malconv_model = MalConv()\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "malconv_model.eval()\n",
    "\n",
    "# Define the input data (replace this with your actual input data)\n",
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.float32)  # Example: single sample of length 2000000\n",
    "\n",
    "# Wrap the input in a torch.autograd.Variable for gradient computation\n",
    "input_var = torch.autograd.Variable(input_data, requires_grad=True)\n",
    "\n",
    "# Forward pass to get the model output\n",
    "output = malconv_model(input_var)\n",
    "\n",
    "# Backward pass to compute gradients\n",
    "output.backward()\n",
    "\n",
    "# Extract gradients from the embedded input\n",
    "embedding_gradients = input_var.grad\n",
    "\n",
    "# Use the GradientExplainer for SHAP values computation\n",
    "explainer = shap.GradientExplainer(malconv_model, input_data)\n",
    "shap_values = explainer.shap_values(input_data, nsamples=200)\n",
    "\n",
    "# Print the SHAP values\n",
    "print(\"SHAP values:\", shap_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7943135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import shap\n",
    "\n",
    "# Define the MalConv model\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.int32)\n",
    "        self.embed_x = self.embed(x)\n",
    "        x = torch.transpose(self.embed_x, -1, -2)\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        x = cnn_value * gating_weight\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the MalConv model\n",
    "malconv_model = MalConv()\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "malconv_model.eval()\n",
    "\n",
    "# Define the input data (replace this with your actual input data)\n",
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.float32)  # Example: single sample of length 2000000\n",
    "\n",
    "# Wrap the input in a torch.autograd.Variable for gradient computation\n",
    "input_var = torch.autograd.Variable(input_data, requires_grad=True)\n",
    "\n",
    "# Forward pass to get the model output\n",
    "output = malconv_model(input_var)\n",
    "\n",
    "# Backward pass to compute gradients with respect to conv_1 layer\n",
    "output.backward()\n",
    "conv_1_gradients = malconv_model.conv_1.weight.grad\n",
    "\n",
    "# Use the GradientExplainer for SHAP values computation\n",
    "explainer = shap.GradientExplainer(malconv_model, input_data)\n",
    "shap_values = explainer.shap_values(input_data, nsamples=200, ranked_outputs=1, output_rank_order=\"max\", return_variances=False)\n",
    "\n",
    "# Print the SHAP values\n",
    "print(\"SHAP values:\", shap_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f1f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "current = os.getcwd()\n",
    "sys.path.append(os.path.join(current,'/home/user/Downloads/shap-master/'))\n",
    "import shap\n",
    "sys.path.remove(os.path.join(current,'/home/user/Downloads/shap-master/'))\n",
    "os.chdir(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82225c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "# Define the MalConv model\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.int32)\n",
    "        self.embed_x = self.embed(x)\n",
    "        x = torch.transpose(self.embed_x, -1, -2)\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        x = cnn_value * gating_weight\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the MalConv model\n",
    "malconv_model = MalConv()\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "malconv_model.eval()\n",
    "\n",
    "# Define the input data (replace this with your actual input data)\n",
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.float32)  # Example: single sample of length 2000000\n",
    "\n",
    "# Wrap the input in a torch.autograd.Variable for gradient computation\n",
    "input_var = torch.autograd.Variable(input_data, requires_grad=True)\n",
    "\n",
    "# Forward pass to get the model output\n",
    "output = malconv_model(input_var)\n",
    "\n",
    "# Backward pass to compute gradients with respect to all layers\n",
    "output.backward()\n",
    "\n",
    "# Use the GradientExplainer for SHAP values computation\n",
    "explainer = shap.GradientExplainer(malconv_model, input_data)\n",
    "\n",
    "# Compute SHAP values for layers that have gradients\n",
    "shap_values = []\n",
    "for layer in malconv_model.children():\n",
    "    if hasattr(layer, 'weight') and layer.weight.grad is not None:\n",
    "        shap_values_layer = explainer.shap_values(input_data, nsamples=200, ranked_outputs=1, output_rank_order=\"max\", return_variances=False)\n",
    "        shap_values.append(shap_values_layer)\n",
    "\n",
    "# Print the SHAP values\n",
    "print(\"SHAP values:\", shap_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e49ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "# Define the MalConv model\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.int32)\n",
    "        self.embed_x = self.embed(x)\n",
    "        x = torch.transpose(self.embed_x, -1, -2)\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        x = cnn_value * gating_weight\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the MalConv model\n",
    "malconv_model = MalConv()\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "malconv_model.eval()\n",
    "\n",
    "# Define the input data (replace this with your actual input data)\n",
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.float32)  # Example: single sample of length 2000000\n",
    "\n",
    "# Wrap the input in a torch.autograd.Variable for gradient computation\n",
    "input_var = torch.autograd.Variable(input_data, requires_grad=True)\n",
    "\n",
    "# Forward pass to get the model output\n",
    "output = malconv_model(input_var)\n",
    "\n",
    "# Backward pass to compute gradients with respect to all layers\n",
    "output.backward()\n",
    "\n",
    "# Use the GradientExplainer for SHAP values computation\n",
    "explainer = shap.GradientExplainer(malconv_model, input_data)\n",
    "\n",
    "# Compute SHAP values for convolutional layers\n",
    "shap_values_conv = explainer.shap_values(input_data, nsamples=200, ranked_outputs=1, output_rank_order=\"max\", return_variances=False)\n",
    "\n",
    "# Compute SHAP values for fully connected layers\n",
    "fc_input = malconv_model.fc_1(malconv_model.pooling(malconv_model.embed_x.narrow(-2, 0, 4)).view(-1, 128))\n",
    "shap_values_fc = explainer.shap_values(fc_input, nsamples=200, ranked_outputs=1, output_rank_order=\"max\", return_variances=False)\n",
    "\n",
    "# Print the SHAP values\n",
    "print(\"SHAP values for convolutional layers:\", shap_values_conv)\n",
    "print(\"SHAP values for fully connected layers:\", shap_values_fc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d5911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "# Define the MalConv model\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.int32)\n",
    "        self.embed_x = self.embed(x)\n",
    "        x = torch.transpose(self.embed_x, -1, -2)\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        x = cnn_value * gating_weight\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the MalConv model\n",
    "malconv_model = MalConv()\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "malconv_model.eval()\n",
    "\n",
    "# Define the input data (replace this with your actual input data)\n",
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.float32)  # Example: single sample of length 2000000\n",
    "\n",
    "# Wrap the input in a torch.autograd.Variable for gradient computation\n",
    "input_var = torch.autograd.Variable(input_data, requires_grad=True)\n",
    "\n",
    "# Forward pass to get the model output\n",
    "output = malconv_model(input_var)\n",
    "\n",
    "# Convert the input data to a NumPy array\n",
    "input_data_numpy = input_data.numpy()\n",
    "\n",
    "# Convert the NumPy array back to a PyTorch tensor with the appropriate data type\n",
    "input_data_tensor = torch.tensor(input_data_numpy, dtype=torch.long)\n",
    "\n",
    "# Use the DeepExplainer for SHAP values computation\n",
    "explainer = shap.DeepExplainer(malconv_model, input_data_tensor)\n",
    "\n",
    "\n",
    "# Compute SHAP values\n",
    "shap_values = explainer.shap_values(input_data)\n",
    "\n",
    "# Print the SHAP values\n",
    "print(\"SHAP values:\", shap_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe53c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "current = os.getcwd()\n",
    "sys.path.append(os.path.join(current,'/home/user/Downloads/shap-master/'))\n",
    "import shap\n",
    "sys.path.remove(os.path.join(current,'/home/user/Downloads/shap-master/'))\n",
    "os.chdir(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e620d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the MalConv model\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.int64)\n",
    "        self.embed_x = self.embed(x)\n",
    "        x = torch.transpose(self.embed_x, -1, -2)\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        x = cnn_value * gating_weight\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the MalConv model\n",
    "malconv_model = MalConv()\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "malconv_model.eval()\n",
    "\n",
    "# Define the input data (replace this with your actual input data)\n",
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.float32)  # Example: single sample of length 2000000\n",
    "\n",
    "# Wrap the input in a torch.autograd.Variable for gradient computation\n",
    "input_var = torch.autograd.Variable(input_data, requires_grad=True)\n",
    "\n",
    "# Forward pass to get the model output\n",
    "output = malconv_model(input_var)\n",
    "\n",
    "# Backward pass to compute gradients with respect to all layers\n",
    "output.backward()\n",
    "\n",
    "# Use the GradientExplainer for SHAP values computation\n",
    "explainer = shap.GradientExplainer(malconv_model, input_var.data)\n",
    "\n",
    "# Compute SHAP values for layers that have gradients\n",
    "shap_values = explainer.shap_values(input_var.data, nsamples=200, ranked_outputs=1, output_rank_order=\"max\", return_variances=False)\n",
    "\n",
    "# Print the SHAP values\n",
    "print(\"SHAP values:\", shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3398a14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "current = os.getcwd()\n",
    "sys.path.append(os.path.join(current,'/home/user/Downloads/shap-master/'))\n",
    "import shap\n",
    "sys.path.remove(os.path.join(current,'/home/user/Downloads/shap-master/'))\n",
    "os.chdir(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65a681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# Define the MalConv model\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # Variable to store gradients\n",
    "        self.gradients = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.int64)\n",
    "        self.embed_x = self.embed(x)\n",
    "        self.embed_x = self.embed_x.detach()\n",
    "        x = torch.transpose(self.embed_x, -1, -2)\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        x = cnn_value * gating_weight\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        # Register a hook to store gradients during backward pass\n",
    "        x.register_hook(self.capture_gradients)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def capture_gradients(self, grad):\n",
    "        self.gradients = grad.clone()\n",
    "\n",
    "# Create an instance of the MalConv model\n",
    "malconv_model = MalConv()\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "malconv_model.eval()\n",
    "\n",
    "# Define the input data (replace this with your actual input data)\n",
    "input_data = torch.randint(0, 257, (10, 2000000), dtype=torch.float32)  # Example: single sample of length 2000000\n",
    "\n",
    "# Wrap the input in a torch.autograd.Variable for gradient computation\n",
    "input_var = torch.autograd.Variable(input_data, requires_grad=True)\n",
    "\n",
    "# Forward pass to get the model output\n",
    "output = malconv_model(input_var)\n",
    "\n",
    "# Backward pass to compute gradients with respect to the output\n",
    "output.backward()\n",
    "\n",
    "# Extract the stored gradients\n",
    "gradients = malconv_model.gradients\n",
    "print(gradients)\n",
    "sys.exit()\n",
    "\n",
    "# Use the GradientExplainer for SHAP values computation\n",
    "explainer = shap.GradientExplainer(malconv_model, input_var.data)\n",
    "\n",
    "# Compute SHAP values using the gradients\n",
    "shap_values = explainer.shap_values(input_var.data, nsamples=200, ranked_outputs=1, output_rank_order=\"max\", return_variances=False, input_background=torch.zeros_like(input_var.data))\n",
    "\n",
    "# Print the SHAP values\n",
    "print(\"SHAP values:\", shap_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9691ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "current = os.getcwd()\n",
    "sys.path.append(os.path.join(current,'/home/user/Downloads/shap-master/'))\n",
    "import shap\n",
    "sys.path.remove(os.path.join(current,'/home/user/Downloads/shap-master/'))\n",
    "os.chdir(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59f7d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "# Define the MalConv model\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.int32)\n",
    "        self.embed_x = self.embed(x)\n",
    "        self.embed_x = self.embed_x.detach()  # Detach to allow gradients through embedding\n",
    "        self.embed_x.requires_grad = True  # Set requires_grad explicitly\n",
    "        x = torch.transpose(self.embed_x, -1, -2)\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        x = cnn_value * gating_weight\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the MalConv model\n",
    "malconv_model = MalConv()\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "malconv_model.eval()\n",
    "\n",
    "# Define the input data (replace this with your actual input data)\n",
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.float32)  # Example: single sample of length 2000000\n",
    "\n",
    "# Wrap the input in a torch.autograd.Variable for gradient computation\n",
    "input_var = torch.autograd.Variable(input_data, requires_grad=True)\n",
    "\n",
    "# Forward pass to get the model output\n",
    "output = malconv_model(input_var)\n",
    "\n",
    "# Backward pass to compute gradients\n",
    "output.backward()\n",
    "\n",
    "# Extract gradients from the embedded input\n",
    "embedding_gradients = input_var.grad\n",
    "\n",
    "# Use the GradientExplainer for SHAP values computation\n",
    "explainer = shap.GradientExplainer(malconv_model, input_data)\n",
    "shap_values = explainer.shap_values(input_data, nsamples=200)\n",
    "\n",
    "# Print the SHAP values\n",
    "print(\"SHAP values:\", shap_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5686b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cc1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "current = os.getcwd()\n",
    "sys.path.append(os.path.join(current,'/home/user/Downloads/shap-master/'))\n",
    "import shap\n",
    "sys.path.remove(os.path.join(current,'/home/user/Downloads/shap-master/'))\n",
    "os.chdir(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cae845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "current = os.getcwd()\n",
    "sys.path.append(os.path.join(current,'/home/user/Downloads/shap-master/'))\n",
    "import shap\n",
    "sys.path.remove(os.path.join(current,'/home/user/Downloads/shap-master/'))\n",
    "os.chdir(current)\n",
    "\n",
    "# Define the MalConv model\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.int32)\n",
    "        self.embed_x = self.embed(x).detach() \n",
    "        x = torch.transpose(self.embed_x, -1, -2)\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        x = cnn_value * gating_weight\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.sigmoid(x)  # Sigmoid layer for SHAP analysis\n",
    "        return x\n",
    "\n",
    "# Create an instance of the MalConv model\n",
    "#malconv_model= torch.load('checkpoint/example_sd_123.model', map_location=torch.device('cpu'))\n",
    "malconv_model = MalConv()\n",
    "# Set the model to evaluation mode\n",
    "malconv_model.eval()\n",
    "\n",
    "# Define the input data (replace this with your actual input data)\n",
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.float32)  # Example: single sample of length 2000000\n",
    "\n",
    "# Wrap the input in a torch.autograd.Variable for gradient computation\n",
    "input_var = torch.autograd.Variable(input_data, requires_grad=True)\n",
    "\n",
    "# Forward pass to get the model output\n",
    "output = malconv_model(input_var)\n",
    "\n",
    "\n",
    "# Use the GradientExplainer for SHAP values computation on the Sigmoid layer\n",
    "explainer = shap.GradientExplainer(malconv_model.sigmoid, input_data)\n",
    "\n",
    "try:\n",
    "    # Attempt to compute SHAP values for the Sigmoid layer\n",
    "    shap_values = explainer.shap_values(input_data)\n",
    "    # Print the SHAP values\n",
    "    print(\"SHAP values computed successfully for the Sigmoid layer.\")\n",
    "    print(\"SHAP values:\", shap_values)\n",
    "except Exception as e:\n",
    "    # Catch and print any exceptions\n",
    "    print(\"Error during SHAP computation for the Sigmoid layer:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d01e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "current = os.getcwd()\n",
    "sys.path.append(os.path.join(current,'/home/user/Downloads/shap-master/'))\n",
    "import shap\n",
    "sys.path.remove(os.path.join(current,'/home/user/Downloads/shap-master/'))\n",
    "os.chdir(current)\n",
    "\n",
    "def hook_fn(name):\n",
    "    def fn(grad):\n",
    "        print(f\"Gradient at {name}:\", grad.shape)\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5ced4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MalConv(\n",
       "  (embed): Embedding(257, 8, padding_idx=0)\n",
       "  (conv_1): Conv1d(4, 128, kernel_size=(500,), stride=(500,))\n",
       "  (conv_2): Conv1d(4, 128, kernel_size=(500,), stride=(500,))\n",
       "  (pooling): MaxPool1d(kernel_size=4000, stride=4000, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc_1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc_2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#malconv_model= torch.load('checkpoint/example_sd_123.model', map_location=torch.device('cpu'))\n",
    "# Define the MalConv model\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.to(dtype=torch.int64)\n",
    "        \n",
    "        \n",
    "        self.embed_x = self.embed(x)#.detach() \n",
    "        print(\"Embedding Output Shape:\", embed_x)\n",
    "        \n",
    "        x = torch.transpose(embed_x, -1, -2)\n",
    "        print(\"Transposed Shape:\", x)\n",
    "        \n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        print(\"Conv1 Output Shape:\", cnn_value)\n",
    "        \n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        print(\"Conv2 Output Shape:\", gating_weight)\n",
    "        \n",
    "        x = cnn_value * gating_weight\n",
    "        print(\"Element-wise Multiplication Shape:\", x)\n",
    "        \n",
    "        x = self.pooling(x)\n",
    "        print(\"Pooling Output Shape:\", x)\n",
    "        \n",
    "        x = x.view(-1, 128)\n",
    "        print(\"Flatten Output Shape:\", x)\n",
    "        \n",
    "        x = self.fc_1(x)\n",
    "        print(\"FC1 Output Shape:\", x)\n",
    "        \n",
    "        x = self.fc_2(x)\n",
    "        print(\"FC2 Output Shape:\", x)\n",
    "        \n",
    "        x = self.sigmoid(x)  # Sigmoid layer for SHAP analysis\n",
    "        print(\"Final Output Shape:\", x)\n",
    "        \n",
    "        return x, embed_x, cnn_value, gating_weight\n",
    "    \n",
    "malconv_model = MalConv()\n",
    "# Set the model to evaluation mode\n",
    "malconv_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67650cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Output Shape: tensor([[[ 0.1362, -0.3657, -0.2005,  ...,  0.5853, -0.4327,  0.4558],\n",
      "         [ 0.7466,  0.3279, -1.2955,  ...,  0.6115, -0.2924, -2.0888],\n",
      "         [-0.6400,  0.4905, -0.0948,  ...,  0.7982, -0.9549,  0.5182],\n",
      "         ...,\n",
      "         [ 0.7281, -0.1915, -1.0471,  ..., -0.0043, -0.9162,  0.3628],\n",
      "         [-0.2629, -0.8880,  0.1971,  ...,  0.8209,  0.2465, -0.2481],\n",
      "         [ 0.0993, -0.6505,  0.1064,  ..., -0.9591, -0.9919,  0.2094]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "Transposed Shape: tensor([[[ 0.1362,  0.7466, -0.6400,  ...,  0.7281, -0.2629,  0.0993],\n",
      "         [-0.3657,  0.3279,  0.4905,  ..., -0.1915, -0.8880, -0.6505],\n",
      "         [-0.2005, -1.2955, -0.0948,  ..., -1.0471,  0.1971,  0.1064],\n",
      "         ...,\n",
      "         [ 0.5853,  0.6115,  0.7982,  ..., -0.0043,  0.8209, -0.9591],\n",
      "         [-0.4327, -0.2924, -0.9549,  ..., -0.9162,  0.2465, -0.9919],\n",
      "         [ 0.4558, -2.0888,  0.5182,  ...,  0.3628, -0.2481,  0.2094]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "Conv1 Output Shape: tensor([[[ 0.2252,  0.2736, -0.1610,  ...,  0.5221,  1.1084, -0.3131],\n",
      "         [-0.3293,  0.2420,  0.1249,  ...,  0.6312, -0.5169, -0.2747],\n",
      "         [-0.2602, -0.0843, -0.9340,  ..., -0.1045, -0.1460,  0.5017],\n",
      "         ...,\n",
      "         [-0.0968,  0.5425, -0.1888,  ..., -0.3953,  0.4491,  1.1725],\n",
      "         [ 1.0279,  0.6599, -0.4334,  ..., -0.7027,  0.3384, -0.3621],\n",
      "         [-0.1249, -0.7704,  0.6788,  ...,  0.5990,  0.1106,  0.1417]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "Conv2 Output Shape: tensor([[[0.2860, 0.4834, 0.5665,  ..., 0.3058, 0.6172, 0.7672],\n",
      "         [0.3884, 0.4475, 0.4743,  ..., 0.3534, 0.5464, 0.6583],\n",
      "         [0.3834, 0.3327, 0.3140,  ..., 0.3808, 0.6347, 0.5625],\n",
      "         ...,\n",
      "         [0.4162, 0.3467, 0.6976,  ..., 0.2910, 0.7120, 0.5752],\n",
      "         [0.7752, 0.5348, 0.5495,  ..., 0.4941, 0.4924, 0.6005],\n",
      "         [0.3670, 0.5250, 0.3631,  ..., 0.3273, 0.4642, 0.6539]]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Element-wise Multiplication Shape: tensor([[[ 0.0644,  0.1322, -0.0912,  ...,  0.1597,  0.6842, -0.2402],\n",
      "         [-0.1279,  0.1083,  0.0593,  ...,  0.2231, -0.2825, -0.1809],\n",
      "         [-0.0998, -0.0280, -0.2933,  ..., -0.0398, -0.0927,  0.2822],\n",
      "         ...,\n",
      "         [-0.0403,  0.1881, -0.1317,  ..., -0.1151,  0.3198,  0.6745],\n",
      "         [ 0.7968,  0.3529, -0.2382,  ..., -0.3472,  0.1666, -0.2175],\n",
      "         [-0.0458, -0.4044,  0.2465,  ...,  0.1960,  0.0513,  0.0926]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Pooling Output Shape: tensor([[[1.2224],\n",
      "         [1.3104],\n",
      "         [1.2606],\n",
      "         [1.4298],\n",
      "         [1.5837],\n",
      "         [1.2206],\n",
      "         [1.2648],\n",
      "         [1.2910],\n",
      "         [1.1514],\n",
      "         [1.4162],\n",
      "         [1.6962],\n",
      "         [1.3131],\n",
      "         [1.2366],\n",
      "         [1.3456],\n",
      "         [1.3416],\n",
      "         [1.4425],\n",
      "         [1.2872],\n",
      "         [1.3211],\n",
      "         [1.1503],\n",
      "         [1.1930],\n",
      "         [1.1531],\n",
      "         [1.3527],\n",
      "         [1.0773],\n",
      "         [1.6102],\n",
      "         [1.4502],\n",
      "         [1.0881],\n",
      "         [1.2282],\n",
      "         [1.2160],\n",
      "         [1.3746],\n",
      "         [1.3260],\n",
      "         [1.1533],\n",
      "         [1.2388],\n",
      "         [1.2752],\n",
      "         [1.6013],\n",
      "         [1.0787],\n",
      "         [1.2837],\n",
      "         [1.5015],\n",
      "         [1.1984],\n",
      "         [1.1410],\n",
      "         [1.2097],\n",
      "         [1.2273],\n",
      "         [1.2003],\n",
      "         [1.1535],\n",
      "         [1.2154],\n",
      "         [1.2172],\n",
      "         [1.0744],\n",
      "         [1.1131],\n",
      "         [1.2181],\n",
      "         [1.3233],\n",
      "         [1.4718],\n",
      "         [1.1138],\n",
      "         [1.1957],\n",
      "         [1.2667],\n",
      "         [1.1820],\n",
      "         [1.1369],\n",
      "         [1.5395],\n",
      "         [1.3102],\n",
      "         [1.3334],\n",
      "         [1.2680],\n",
      "         [1.5345],\n",
      "         [1.2043],\n",
      "         [1.1543],\n",
      "         [1.2726],\n",
      "         [1.2801],\n",
      "         [1.0217],\n",
      "         [1.2349],\n",
      "         [1.3711],\n",
      "         [1.0983],\n",
      "         [1.2019],\n",
      "         [1.2315],\n",
      "         [1.0056],\n",
      "         [1.6191],\n",
      "         [1.2039],\n",
      "         [1.4522],\n",
      "         [1.2783],\n",
      "         [1.3623],\n",
      "         [1.5892],\n",
      "         [1.3959],\n",
      "         [1.5079],\n",
      "         [1.1744],\n",
      "         [1.0493],\n",
      "         [1.3934],\n",
      "         [1.1602],\n",
      "         [1.2617],\n",
      "         [1.3948],\n",
      "         [1.2011],\n",
      "         [1.2933],\n",
      "         [1.3566],\n",
      "         [1.1687],\n",
      "         [1.1302],\n",
      "         [1.4385],\n",
      "         [1.2314],\n",
      "         [1.2283],\n",
      "         [1.3944],\n",
      "         [1.2111],\n",
      "         [1.1536],\n",
      "         [1.1276],\n",
      "         [1.1026],\n",
      "         [1.2370],\n",
      "         [1.2416],\n",
      "         [1.0683],\n",
      "         [1.3423],\n",
      "         [1.1223],\n",
      "         [1.1421],\n",
      "         [1.1990],\n",
      "         [1.3436],\n",
      "         [1.3850],\n",
      "         [1.2609],\n",
      "         [1.2175],\n",
      "         [1.3948],\n",
      "         [1.5630],\n",
      "         [1.4416],\n",
      "         [1.2164],\n",
      "         [1.3437],\n",
      "         [1.3706],\n",
      "         [1.5850],\n",
      "         [1.1288],\n",
      "         [1.5694],\n",
      "         [1.2045],\n",
      "         [1.1601],\n",
      "         [1.0637],\n",
      "         [1.2229],\n",
      "         [1.4452],\n",
      "         [1.0927],\n",
      "         [1.4405],\n",
      "         [1.2166],\n",
      "         [1.3015],\n",
      "         [1.3883]]], grad_fn=<SqueezeBackward1>)\n",
      "Flatten Output Shape: tensor([[1.2224, 1.3104, 1.2606, 1.4298, 1.5837, 1.2206, 1.2648, 1.2910, 1.1514,\n",
      "         1.4162, 1.6962, 1.3131, 1.2366, 1.3456, 1.3416, 1.4425, 1.2872, 1.3211,\n",
      "         1.1503, 1.1930, 1.1531, 1.3527, 1.0773, 1.6102, 1.4502, 1.0881, 1.2282,\n",
      "         1.2160, 1.3746, 1.3260, 1.1533, 1.2388, 1.2752, 1.6013, 1.0787, 1.2837,\n",
      "         1.5015, 1.1984, 1.1410, 1.2097, 1.2273, 1.2003, 1.1535, 1.2154, 1.2172,\n",
      "         1.0744, 1.1131, 1.2181, 1.3233, 1.4718, 1.1138, 1.1957, 1.2667, 1.1820,\n",
      "         1.1369, 1.5395, 1.3102, 1.3334, 1.2680, 1.5345, 1.2043, 1.1543, 1.2726,\n",
      "         1.2801, 1.0217, 1.2349, 1.3711, 1.0983, 1.2019, 1.2315, 1.0056, 1.6191,\n",
      "         1.2039, 1.4522, 1.2783, 1.3623, 1.5892, 1.3959, 1.5079, 1.1744, 1.0493,\n",
      "         1.3934, 1.1602, 1.2617, 1.3948, 1.2011, 1.2933, 1.3566, 1.1687, 1.1302,\n",
      "         1.4385, 1.2314, 1.2283, 1.3944, 1.2111, 1.1536, 1.1276, 1.1026, 1.2370,\n",
      "         1.2416, 1.0683, 1.3423, 1.1223, 1.1421, 1.1990, 1.3436, 1.3850, 1.2609,\n",
      "         1.2175, 1.3948, 1.5630, 1.4416, 1.2164, 1.3437, 1.3706, 1.5850, 1.1288,\n",
      "         1.5694, 1.2045, 1.1601, 1.0637, 1.2229, 1.4452, 1.0927, 1.4405, 1.2166,\n",
      "         1.3015, 1.3883]], grad_fn=<ViewBackward0>)\n",
      "FC1 Output Shape: tensor([[ 2.4207e-01, -3.0650e-01, -1.0154e+00,  1.4389e+00,  3.8754e-01,\n",
      "          3.3564e-01,  7.8806e-02,  6.9953e-01, -8.6187e-01,  1.2746e+00,\n",
      "         -1.0697e+00,  1.1509e-01,  7.3426e-01, -6.6933e-01,  2.0355e-02,\n",
      "          7.5539e-01, -3.0517e-02,  1.4612e-01,  1.2963e+00,  2.9633e-01,\n",
      "         -6.2658e-01, -5.5135e-01,  1.1166e-01,  2.0405e-01,  9.8759e-01,\n",
      "          1.3954e+00, -2.4704e-01, -7.8166e-01, -4.7564e-01,  1.6560e-02,\n",
      "         -8.0694e-01, -1.9625e-01,  5.3009e-01, -3.8837e-02,  1.3155e+00,\n",
      "         -2.2032e-01, -8.1869e-04,  5.8984e-01, -1.9221e-01, -6.1838e-01,\n",
      "          3.1763e-01, -9.4469e-02, -7.8859e-01, -1.3119e+00,  1.6844e-01,\n",
      "         -4.4574e-01, -2.8735e-01, -7.7194e-03,  1.8931e-01, -6.9835e-01,\n",
      "         -3.4473e-01,  2.3785e-01,  4.5003e-02, -2.1570e-01, -1.9132e-01,\n",
      "         -9.1897e-01,  3.9902e-01,  2.5024e-01, -9.0563e-01,  2.7202e-01,\n",
      "         -1.1141e-01, -2.5660e-01,  6.6364e-01, -2.2297e-01,  7.6808e-01,\n",
      "          6.5113e-01, -7.4632e-01,  7.8403e-01,  2.9205e-01, -8.0261e-02,\n",
      "         -4.9352e-01,  8.5518e-01,  1.7662e-01, -1.0850e+00,  5.0010e-01,\n",
      "         -7.1872e-01,  6.5416e-01, -3.5920e-01, -1.3091e+00, -4.3044e-01,\n",
      "          4.3436e-02, -8.1347e-02, -2.7227e-01, -2.6096e-01,  2.0714e-02,\n",
      "          3.2083e-01,  1.4739e-01, -2.1010e-01, -6.7501e-01,  1.7817e-01,\n",
      "         -7.3192e-01,  5.9690e-01, -2.9871e-01, -1.1261e+00, -9.8493e-01,\n",
      "         -6.2000e-01,  1.1410e+00, -9.6222e-01, -8.2352e-01, -1.3878e+00,\n",
      "          1.2954e+00,  1.9551e+00,  8.2795e-01, -5.5614e-01,  2.6325e-01,\n",
      "          1.0307e-01,  7.6530e-01, -5.8395e-01,  1.0632e+00,  4.2537e-01,\n",
      "         -6.4750e-01,  2.6882e-01, -3.2250e-01,  1.3346e-01,  6.0588e-01,\n",
      "          5.5191e-01,  5.8924e-02,  1.1576e+00, -1.2488e-01,  1.9460e+00,\n",
      "         -3.2125e-01,  2.9194e-01,  5.7327e-01, -3.1422e-01, -4.2325e-01,\n",
      "         -1.0588e+00, -8.6816e-02,  4.8715e-02]], grad_fn=<AddmmBackward0>)\n",
      "FC2 Output Shape: tensor([[-0.0796]], grad_fn=<AddmmBackward0>)\n",
      "Final Output Shape: tensor([[0.4801]], grad_fn=<SigmoidBackward0>)\n",
      "Output Shape: torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.float32, requires_grad=True)  # Example: single sample of length 2000000\n",
    "\n",
    "# Wrap the input in a torch.autograd.Variable for gradient computation\n",
    "input_var = torch.autograd.Variable(input_data.to(torch.float32), requires_grad=True)\n",
    "output, embed_x, cnn_value, gating_weight = malconv_model(input_data)\n",
    "print(\"Output Shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187c92e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hooks = []\n",
    "\n",
    "hooks.append(input_var.register_hook(hook_fn(\"Input Data\")))\n",
    "hooks.append(embed_x.register_hook(hook_fn(\"Embedding Output\")))\n",
    "hooks.append(cnn_value.register_hook(hook_fn(\"Conv1 Output\")))\n",
    "hooks.append(gating_weight.register_hook(hook_fn(\"Conv2 Output\")))\n",
    "hooks.append(output.register_hook(hook_fn(\"Final Output\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca72fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b3dd9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Shape: torch.Size([1, 1])\n",
      "tensor(0.7337, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "target = torch.tensor([1.0]).view_as(output)  # or the appropriate target for your task\n",
    "print(\"Target Shape:\", target.shape)\n",
    "loss = loss_fn(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cc764f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Extract gradients\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#import torch.autograd as autograd\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "\n",
    "loss.backward()\n",
    "# Extract gradients\n",
    "#import torch.autograd as autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afb6b98b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MalConv' object has no attribute 'embed_x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m w \u001b[38;5;241m=\u001b[39m \u001b[43mmalconv_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_x\u001b[49m\u001b[38;5;241m.\u001b[39mgrad[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m      2\u001b[0m w\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MalConv' object has no attribute 'embed_x'"
     ]
    }
   ],
   "source": [
    "w = malconv_model.embed_x.grad[0].data\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "899befc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Shape: torch.Size([1, 1])\n",
      "Gradient of Input Data (x) with respect to Loss:\n",
      "torch.Size([1, 2000000, 1])\n",
      "torch.Size([1, 2000000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "current = os.getcwd()\n",
    "sys.path.append(os.path.join(current,'/home/user/Downloads/shap-master/'))\n",
    "import shap\n",
    "sys.path.remove(os.path.join(current,'/home/user/Downloads/shap-master/'))\n",
    "os.chdir(current)\n",
    "\n",
    "def hook_fn(name):\n",
    "    def fn(grad):\n",
    "        hook_fn.saved_gradient = grad\n",
    "    return fn\n",
    "\n",
    "hook_fn.saved_gradient = None\n",
    "\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.to(dtype=torch.int64)\n",
    "        \n",
    "        embed_x = self.embed(x)\n",
    "        embed_x.register_hook(hook_fn(\"Embedding Output\"))\n",
    "        \n",
    "        x = torch.transpose(embed_x, -1, -2)\n",
    "\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        \n",
    "        x = cnn_value * gating_weight  \n",
    "        \n",
    "        x = self.pooling(x)\n",
    "\n",
    "        x = x.view(-1, 128)     \n",
    "        \n",
    "        x = self.fc_1(x)\n",
    "        \n",
    "        x = self.fc_2(x)\n",
    "\n",
    "        x = self.sigmoid(x)  # Sigmoid layer for SHAP analysis\n",
    "\n",
    "        return x\n",
    "    \n",
    "malconv_model = MalConv()\n",
    "# Set the model to evaluation mode\n",
    "malconv_model.eval()\n",
    "\n",
    "#hook = malconv_model.embed.register_forward_hook(hook_fn)\n",
    "\n",
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.float32, requires_grad=True)  # Example: single sample of length 2000000\n",
    "\n",
    "output = malconv_model(input_data)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "target = torch.tensor([1.0]).view_as(output)  # or the appropriate target for your task\n",
    "print(\"Target Shape:\", target.shape)\n",
    "loss = loss_fn(output, target)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "grad_x = hook_fn.saved_gradient.sum(dim=-1, keepdim=True)\n",
    "print(\"Gradient of Input Data (x) with respect to Loss:\")\n",
    "print(grad_x.shape)\n",
    "\n",
    "grad_x = grad_x.squeeze(dim=-1)\n",
    "print(grad_x.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73b21641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of Input Data (x) with respect to Loss:\n",
      "torch.Size([1, 2000000, 1])\n"
     ]
    }
   ],
   "source": [
    "grad_x = hook_fn.saved_gradient.sum(dim=-1, keepdim=True)\n",
    "print(\"Gradient of Input Data (x) with respect to Loss:\")\n",
    "print(grad_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "983daaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "grad_x = grad_x.squeeze(dim=-1)\n",
    "grad_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d58f3800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "numpy_array = grad_x.numpy()\n",
    "df = pd.DataFrame(numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42a7de74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999995</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999996</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999997</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999998</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999999</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000000 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "...      ...\n",
       "1999995  0.0\n",
       "1999996  0.0\n",
       "1999997  0.0\n",
       "1999998  0.0\n",
       "1999999  0.0\n",
       "\n",
       "[2000000 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df.transpose()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae4c99ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(test[test.columns[0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "317f0813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.080572546"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test.columns[0]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31469940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "current = os.getcwd()\n",
    "sys.path.append(os.path.join(current,'/home/user/Downloads/shap-master/'))\n",
    "import shap\n",
    "sys.path.remove(os.path.join(current,'/home/user/Downloads/shap-master/'))\n",
    "os.chdir(current)\n",
    "\n",
    "load_malconv = torch.load('checkpoint/example_sd_123.model', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a664bb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "load_malconv.eval() \n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    def fn(grad):\n",
    "        hook_fn.saved_gradient = grad\n",
    "    return fn\n",
    "hook = load_malconv.embed.register_forward_hook(hook_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cb27417",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "transpose() received an invalid combination of arguments - got (function, int, int), but expected one of:\n * (Tensor input, int dim0, int dim1)\n      didn't match because some of the arguments have invalid types: (!function!, int, int)\n * (Tensor input, name dim0, name dim1)\n      didn't match because some of the arguments have invalid types: (!function!, !int!, !int!)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m input_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m257\u001b[39m, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2000000\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Example: single sample of length 2000000\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mload_malconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()\n\u001b[1;32m      6\u001b[0m target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1.0\u001b[39m])\u001b[38;5;241m.\u001b[39mview_as(output)  \u001b[38;5;66;03m# or the appropriate target for your task\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/Explainability/GradDesc/src/model.py:34\u001b[0m, in \u001b[0;36mMalConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m embed_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed(x)    \u001b[38;5;66;03m# Channel first  .to(dtype = torch.int32)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#self.embed_x=self.embed_x.detach()     # embed detach\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# embed_x.requires_grad=True\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#embed_x.register_hook(hook_fn(\"Embedding Output\"))\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43membed_x\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m cnn_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_1(x\u001b[38;5;241m.\u001b[39mnarrow(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m     37\u001b[0m gating_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_2(x\u001b[38;5;241m.\u001b[39mnarrow(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m)))\n",
      "\u001b[0;31mTypeError\u001b[0m: transpose() received an invalid combination of arguments - got (function, int, int), but expected one of:\n * (Tensor input, int dim0, int dim1)\n      didn't match because some of the arguments have invalid types: (!function!, int, int)\n * (Tensor input, name dim0, name dim1)\n      didn't match because some of the arguments have invalid types: (!function!, !int!, !int!)\n"
     ]
    }
   ],
   "source": [
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.float32, requires_grad=True)  # Example: single sample of length 2000000\n",
    "\n",
    "output = load_malconv(input_data)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "target = torch.tensor([1.0]).view_as(output)  # or the appropriate target for your task\n",
    "print(\"Target Shape:\", target.shape)\n",
    "loss = loss_fn(output, target)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "grad_x = hook_fn.saved_gradient.sum(dim=-1, keepdim=True)\n",
    "print(\"Gradient of Input Data (x) with respect to Loss:\")\n",
    "print(grad_x.shape)\n",
    "\n",
    "grad_x = grad_x.squeeze(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "636ce288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Shape: torch.Size([1, 1])\n",
      "Gradient of Input Data (x) with respect to Loss:\n",
      "torch.Size([1, 2000000, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "current = os.getcwd()\n",
    "sys.path.append(os.path.join(current,'/home/user/Downloads/shap-master/'))\n",
    "import shap\n",
    "sys.path.remove(os.path.join(current,'/home/user/Downloads/shap-master/'))\n",
    "os.chdir(current)\n",
    "\n",
    "def hook_fn(name):\n",
    "    def fn(grad):\n",
    "        hook_fn.saved_gradient = grad\n",
    "    return fn\n",
    "\n",
    "hook_fn.saved_gradient = None\n",
    "\n",
    "class MalConv(nn.Module):\n",
    "    def __init__(self, input_length=2000000, window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        self.fc_1 = nn.Linear(128, 128)\n",
    "        self.fc_2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.hook_handle = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(dtype=torch.int64)\n",
    "        embed_x = self.embed(x)\n",
    "        \n",
    "        if self.hook_handle is None:\n",
    "            self.hook_handle = embed_x.register_hook(hook_fn(\"Embedding Output\"))\n",
    "        \n",
    "        x = torch.transpose(embed_x, -1, -2)\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "        x = cnn_value * gating_weight  \n",
    "        x = self.pooling(x)\n",
    "        x = x.view(-1, 128)       \n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.sigmoid(x)  # Sigmoid layer for SHAP analysis\n",
    "        return x\n",
    "    \n",
    "    def remove_hook(self):\n",
    "        if self.hook_handle is not None:\n",
    "            self.hook_handle.remove()\n",
    "            self.hook_handle = None\n",
    "    \n",
    "malconv_model = MalConv()\n",
    "# Set the model to evaluation mode\n",
    "malconv_model.eval()\n",
    "\n",
    "#hook = malconv_model.embed.register_forward_hook(hook_fn)\n",
    "\n",
    "input_data = torch.randint(0, 257, (1, 2000000), dtype=torch.float32, requires_grad=True)  # Example: single sample of length 2000000\n",
    "\n",
    "output = malconv_model(input_data)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "target = torch.tensor([1.0]).view_as(output)  # or the appropriate target for your task\n",
    "print(\"Target Shape:\", target.shape)\n",
    "loss = loss_fn(output, target)\n",
    "\n",
    "loss.backward()\n",
    "malconv_model.remove_hook()\n",
    "\n",
    "grad_x = hook_fn.saved_gradient.sum(dim=-1, keepdim=True)\n",
    "print(\"Gradient of Input Data (x) with respect to Loss:\")\n",
    "print(grad_x.shape)\n",
    "\n",
    "grad_x = grad_x.squeeze(dim=-1)\n",
    "\n",
    "grad_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946edaeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
