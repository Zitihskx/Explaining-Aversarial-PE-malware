{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.util import ExeDataset, write_pred\n",
    "from src.model import MalConv\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "sys.path.append('/home/user/Downloads/shap-master/')\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file for experiment\n",
    "\n",
    "config_path = 'config/example.yaml' #needs to modify to point to a new list of valid label\n",
    "seed = int(123)\n",
    "conf = yaml.load(open(config_path, 'r'), Loader = yaml.SafeLoader)\n",
    "\n",
    "use_gpu = conf['use_gpu']\n",
    "use_cpu = conf['use_cpu']\n",
    "exp_name = conf['exp_name'] + '_sd_' + str(seed)\n",
    "\n",
    "valid_data_path = conf['valid_data_path']\n",
    "valid_label_path = conf['valid_label_path']\n",
    "\n",
    "checkpoint_dir = conf['checkpoint_dir']\n",
    "chkpt_acc_path = checkpoint_dir + exp_name + '.model'\n",
    "\n",
    "val_label_table = pd.read_csv(valid_label_path, header=None, index_col=0)\n",
    "\n",
    "val_label_table.index = val_label_table.index.str.upper()\n",
    "val_label_table = val_label_table.rename(columns={1: 'ground_truth'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_table = val_label_table.groupby(level=0).last()\n",
    "#del val_label_table\n",
    "\n",
    "validloader = DataLoader(ExeDataset(list(val_table.index), valid_data_path, list(val_table.ground_truth)),\n",
    "                         batch_size=1, shuffle=False, num_workers=use_cpu)\n",
    "\n",
    "malconv = torch.load('checkpoint/example_sd_123.model', map_location=torch.device('cpu'))\n",
    "\n",
    "print(\"Loading MalConv model successful\")\n",
    "\n",
    "history = {}\n",
    "history['val_loss'] = []\n",
    "history['val_acc'] = []\n",
    "history['val_pred'] = []\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "total=0\n",
    "evade = 0\n",
    "changes=[]\n",
    "temp_df = pd.DataFrame(columns=['exe_input'])\n",
    "tensor_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "for _, val_batch_data in enumerate(validloader):\n",
    "    # total+=1\n",
    "    # print(total)\n",
    "    cur_batch_size = val_batch_data[0].size(0)\n",
    "    #print(\"cur batch size:\", cur_batch_size)\n",
    "\n",
    "    exe_input = val_batch_data[0].cuda() if use_gpu else val_batch_data[0]\n",
    "\n",
    "    data = exe_input[0].cpu().numpy()\n",
    "\n",
    "    length = data[-1]\n",
    "  \n",
    "    data = data[:length]\n",
    "    if length>2000000:\n",
    "        continue\n",
    "\n",
    "    # array_0 = np.full(2000000,0)\n",
    "    # array_1 = np.full(2000000,256)\n",
    "    # array_random = np.random.randint(0, 256, 2000000)\n",
    "\n",
    "    data = np.concatenate([data, np.random.randint(0, 256, 2000000 - length)])\n",
    "\n",
    "    init_prob = 0\n",
    " \n",
    "    label = val_batch_data[1].cuda() if use_gpu else val_batch_data[1]\n",
    " \n",
    "    label = Variable(label.float(), requires_grad=False)\n",
    "\n",
    "    label = Variable(torch.from_numpy(np.array([[0]])).float(), requires_grad=False)\n",
    "\n",
    "    embed = malconv.embed\n",
    "    sigmoid = nn.Sigmoid()\n",
    "    count_j = 0\n",
    "    t=0\n",
    "\n",
    "    exe_input = torch.from_numpy(np.array([data]))\n",
    "    exe_input = Variable(exe_input.long(), requires_grad=False)\n",
    "\n",
    "    exe_input = exe_input.to(dtype = torch.float32)\n",
    "    # pred = malconv(exe_input)\n",
    "    # prob = sigmoid(pred).cpu().data.numpy()[0][0]\n",
    " \n",
    "\n",
    "    # array_0_tensor = torch.from_numpy(np.array([array_0]))\n",
    "    # array_0_tensor = Variable(array_0_tensor.long(), requires_grad=False)\n",
    "\n",
    "    # array_1_tensor = torch.from_numpy(np.array([array_1]))\n",
    "    # array_1_tensor = Variable(array_1_tensor.long(), requires_grad=False)\n",
    "\n",
    "    # array_random_tensor = torch.from_numpy(np.array([array_random]))\n",
    "    # array_random_tensor = Variable(array_random_tensor.long(), requires_grad=False)\n",
    "    # temp_df = temp_df.append({'exe_input':exe_input}, ignore_index=True)\n",
    "\n",
    "    tensor_list.append(exe_input)\n",
    "    total += 1\n",
    "    if total>12:\n",
    "        sys.exit()\n",
    "    if total%10==0:\n",
    "        print(total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(tensor_list[0:1])\n",
    "background = torch.stack(tensor_list[0:10], dim = 0)\n",
    "background.shape\n",
    "#explainer = shap.DeepExplainer(malconv, background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#tensor_list[0:1][0].size()\n",
    "background = background.squeeze(1)\n",
    "background.shape\n",
    "\n",
    "#explainer = shap.DeepExplainer(malconv, background)\n",
    "#explainer = shap.DeepExplainer(malconv, background)\n",
    "# batch = torch.cat(tensor_list[0:10], dim=0)\n",
    "# batch = batch.unsqueeze(1)\n",
    "# batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(malconv.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Shap model taking malconv and background data as input\n",
    "# def model_predict(data):\n",
    "#     malconv.eval()\n",
    "#     with torch.no_grad():\n",
    "#         output = malconv(torch.LongTensor(data))\n",
    "#     return output.numpy()\n",
    "\n",
    "explainer = shap.GradientExplainer(malconv, background)\n",
    "\n",
    "#explainer = shap.GradientExplainer(malconv, background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(explainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = torch.stack(tensor_list[10:11],dim=0)\n",
    "test_tensor = test_tensor.squeeze(1)\n",
    "test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_tensor.shape\n",
    "shap_values = explainer.shap_values(test_tensor.to(dtype = torch.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.sum(shap_values[0]))\n",
    "\n",
    "# np.savetxt('myfilesave.txt',shap_values[0], delimiter='\\t')\n",
    "# print(np.sum(shap_values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('myfilesave.txt', shap_values[0], delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shap_values = explainer.shap_values(test_float_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values = explainer.shap_values(test_float_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
