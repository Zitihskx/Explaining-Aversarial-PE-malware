{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "537f0ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN deepexplainer for mnist for reference\n",
    "import sys\n",
    "import torch, torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "sys.path.append('/home/user/Downloads/shap-master/')\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "251b55a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/home/user/Downloads/digit-recognizer/train.csv\",dtype = np.float32)\n",
    "\n",
    "\n",
    "target = train.label.values\n",
    "train = train.loc[:,train.columns != \"label\"].values/255 \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size = 0.2, random_state = 42) \n",
    "\n",
    "X_train = torch.from_numpy(X_train)\n",
    "y_train = torch.from_numpy(y_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_test = torch.from_numpy(y_test).type(torch.LongTensor) # data type is long\n",
    "\n",
    "batch_size = 128\n",
    "num_epochs = 100\n",
    "\n",
    "train = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ac77785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500  Loss: 0.05368156358599663  Accuracy: 97.27380952380952 %\n",
      "Iteration: 1000  Loss: 0.08291641622781754  Accuracy: 97.3452380952381 %\n",
      "Iteration: 1500  Loss: 0.020846867933869362  Accuracy: 98.04761904761905 %\n",
      "Iteration: 2000  Loss: 0.03601455315947533  Accuracy: 98.10714285714286 %\n",
      "Iteration: 2500  Loss: 0.0795823261141777  Accuracy: 98.35714285714286 %\n",
      "Iteration: 3000  Loss: 0.02818145789206028  Accuracy: 98.1547619047619 %\n",
      "Iteration: 3500  Loss: 0.03383674472570419  Accuracy: 98.5 %\n",
      "Iteration: 4000  Loss: 0.020079368725419044  Accuracy: 98.60714285714286 %\n",
      "Iteration: 4500  Loss: 0.018265660852193832  Accuracy: 98.42857142857143 %\n",
      "Iteration: 5000  Loss: 0.012500529177486897  Accuracy: 98.64285714285714 %\n",
      "Iteration: 5500  Loss: 0.03243377059698105  Accuracy: 98.45238095238095 %\n",
      "Iteration: 6000  Loss: 0.003825186751782894  Accuracy: 98.64285714285714 %\n",
      "Iteration: 6500  Loss: 0.011302103288471699  Accuracy: 98.75 %\n",
      "Iteration: 7000  Loss: 0.0049913981929421425  Accuracy: 98.67857142857143 %\n",
      "Iteration: 7500  Loss: 0.01566493883728981  Accuracy: 98.57142857142857 %\n",
      "Iteration: 8000  Loss: 0.0037861214950680733  Accuracy: 98.41666666666667 %\n",
      "Iteration: 8500  Loss: 0.017579834908246994  Accuracy: 98.3452380952381 %\n",
      "Iteration: 9000  Loss: 0.009867885150015354  Accuracy: 98.70238095238095 %\n",
      "Iteration: 9500  Loss: 0.002077005570754409  Accuracy: 98.55952380952381 %\n",
      "Iteration: 10000  Loss: 0.0028298625256866217  Accuracy: 98.70238095238095 %\n",
      "Iteration: 10500  Loss: 0.0075503322295844555  Accuracy: 98.60714285714286 %\n",
      "Iteration: 11000  Loss: 0.0037570251151919365  Accuracy: 98.60714285714286 %\n",
      "Iteration: 11500  Loss: 0.0019454930443316698  Accuracy: 98.77380952380952 %\n",
      "Iteration: 12000  Loss: 0.003959718160331249  Accuracy: 98.66666666666667 %\n",
      "Iteration: 12500  Loss: 0.006192029919475317  Accuracy: 98.70238095238095 %\n",
      "Iteration: 13000  Loss: 0.0034290000330656767  Accuracy: 98.52380952380952 %\n",
      "Iteration: 13500  Loss: 0.0016720602288842201  Accuracy: 98.52380952380952 %\n",
      "Iteration: 14000  Loss: 0.0010388110531494021  Accuracy: 98.69047619047619 %\n",
      "Iteration: 14500  Loss: 0.0005474314093589783  Accuracy: 98.6547619047619 %\n",
      "Iteration: 15000  Loss: 0.0002301111671840772  Accuracy: 98.67857142857143 %\n",
      "Iteration: 15500  Loss: 0.0007454691221937537  Accuracy: 98.70238095238095 %\n",
      "Iteration: 16000  Loss: 0.0020333188585937023  Accuracy: 98.60714285714286 %\n",
      "Iteration: 16500  Loss: 0.0010109988506883383  Accuracy: 98.63095238095238 %\n",
      "Iteration: 17000  Loss: 0.002272512996569276  Accuracy: 98.72619047619048 %\n",
      "Iteration: 17500  Loss: 0.0001549294393043965  Accuracy: 98.61904761904762 %\n",
      "Iteration: 18000  Loss: 0.001497271005064249  Accuracy: 98.64285714285714 %\n",
      "Iteration: 18500  Loss: 0.0013934522867202759  Accuracy: 98.67857142857143 %\n",
      "Iteration: 19000  Loss: 0.0005420822417363524  Accuracy: 98.73809523809524 %\n",
      "Iteration: 19500  Loss: 0.0004081113438587636  Accuracy: 98.77380952380952 %\n",
      "Iteration: 20000  Loss: 0.0003167226677760482  Accuracy: 98.70238095238095 %\n",
      "Iteration: 20500  Loss: 0.000701237702742219  Accuracy: 98.71428571428571 %\n",
      "Iteration: 21000  Loss: 0.001273393165320158  Accuracy: 98.67857142857143 %\n",
      "Iteration: 21500  Loss: 3.601675052777864e-05  Accuracy: 98.61904761904762 %\n",
      "Iteration: 22000  Loss: 0.0005277273012325168  Accuracy: 98.72619047619048 %\n",
      "Iteration: 22500  Loss: 0.00012010119098704308  Accuracy: 98.64285714285714 %\n",
      "Iteration: 23000  Loss: 0.0001699682034086436  Accuracy: 98.70238095238095 %\n",
      "Iteration: 23500  Loss: 0.0007866969099268317  Accuracy: 98.66666666666667 %\n",
      "Iteration: 24000  Loss: 0.00018690507567953318  Accuracy: 98.78571428571429 %\n",
      "Iteration: 24500  Loss: 0.000781128415837884  Accuracy: 98.79761904761905 %\n",
      "Iteration: 25000  Loss: 0.0005090072518214583  Accuracy: 98.71428571428571 %\n",
      "Iteration: 25500  Loss: 0.000494153646286577  Accuracy: 98.75 %\n",
      "Iteration: 26000  Loss: 0.0002862134715542197  Accuracy: 98.78571428571429 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(32 * 4 * 4, 10) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.maxpool1(out)\n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.maxpool2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        return out\n",
    "    \n",
    "# Create CNN\n",
    "model = CNNModel()\n",
    "\n",
    "# Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# CNN model training\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        train = Variable(images.view(-1, 1, 28, 28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad() # Clear gradients\n",
    "        outputs = model(train) # Forward propagation\n",
    "        loss = error(outputs, labels) # Calculate softmax and cross entropy loss\n",
    "        loss.backward() # Calculating gradients\n",
    "        optimizer.step() # Update parameters\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        if count % 50 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            # Predict test dataset\n",
    "            for images, labels in test_loader:\n",
    "                test = Variable(images.view(-1, 1, 28, 28))\n",
    "                outputs = model(test) # Forward propagation\n",
    "                predicted = torch.max(outputs.data, 1)[1] # Get predictions from the maximum value\n",
    "                total += len(labels) # Total number of labels\n",
    "                correct += (predicted == labels).sum() # Total correct predictions\n",
    "            \n",
    "            accuracy = 100.0 * correct.item() / total\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data.item())\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "            if count % 500 == 0:\n",
    "                print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data.item(), accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "626c62d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (int) and bias type (float) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m background \u001b[38;5;241m=\u001b[39m images[:\u001b[38;5;241m100\u001b[39m]\n\u001b[1;32m      6\u001b[0m test_images\u001b[38;5;241m=\u001b[39m images[\u001b[38;5;241m100\u001b[39m:\u001b[38;5;241m110\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m e \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDeepExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mshap_values(test_images)\n",
      "File \u001b[0;32m~/Downloads/shap-master/shap/explainers/_deep/__init__.py:86\u001b[0m, in \u001b[0;36mDeepExplainer.__init__\u001b[0;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m TFDeep(model, data, session, learning_phase_flags)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m \u001b[43mPyTorchDeep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer\u001b[38;5;241m.\u001b[39mexpected_value\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m=\u001b[39m framework\n",
      "File \u001b[0;32m~/Downloads/shap-master/shap/explainers/_deep/deep_pytorch.py:62\u001b[0m, in \u001b[0;36mPyTorchDeep.__init__\u001b[0;34m(self, model, data, debug)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     60\u001b[0m     data_int \u001b[38;5;241m=\u001b[39m [tensor\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mint) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m data] \u001b[38;5;66;03m#Added extra line to convert tensor to int\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata_int\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# also get the device everything is running on\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mdevice\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mCNNModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 13\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu1(out)\n\u001b[1;32m     15\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool1(out)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (int) and bias type (float) should be the same"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch = next(iter(test_loader))\n",
    "images, _ = batch\n",
    "images = images.view(-1, 1, 28, 28)\n",
    "\n",
    "background = images[:100]\n",
    "test_images= images[100:110]\n",
    "\n",
    "e = shap.DeepExplainer(model, images)\n",
    "shap_values = e.shap_values(test_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3d8c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
