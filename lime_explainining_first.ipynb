{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.util import ExeDataset, write_pred\n",
    "from src.model import MalConv\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "from lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file for experiment\n",
    "\n",
    "config_path = 'config/example.yaml' #needs to modify to point to a new list of valid label\n",
    "seed = int(123)\n",
    "conf = yaml.load(open(config_path, 'r'), Loader = yaml.SafeLoader)\n",
    "\n",
    "use_gpu = conf['use_gpu']\n",
    "use_cpu = conf['use_cpu']\n",
    "exp_name = conf['exp_name'] + '_sd_' + str(seed)\n",
    "\n",
    "valid_data_path = conf['valid_data_path']\n",
    "valid_label_path = conf['valid_label_path']\n",
    "\n",
    "checkpoint_dir = conf['checkpoint_dir']\n",
    "chkpt_acc_path = checkpoint_dir + exp_name + '.model'\n",
    "\n",
    "val_label_table = pd.read_csv(valid_label_path, header=None, index_col=0)\n",
    "\n",
    "val_label_table.index = val_label_table.index.str.upper()\n",
    "val_label_table = val_label_table.rename(columns={1: 'ground_truth'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MalConv model successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.9/site-packages/torch/serialization.py:888: SourceChangeWarning: source code of class 'src.model.MalConv' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/anaconda3/lib/python3.9/site-packages/torch/serialization.py:888: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/anaconda3/lib/python3.9/site-packages/torch/serialization.py:888: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv1d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/anaconda3/lib/python3.9/site-packages/torch/serialization.py:888: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool1d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/anaconda3/lib/python3.9/site-packages/torch/serialization.py:888: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/user/anaconda3/lib/python3.9/site-packages/torch/serialization.py:888: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Sigmoid' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "val_table = val_label_table.groupby(level=0).last()\n",
    "#del val_label_table\n",
    "\n",
    "validloader = DataLoader(ExeDataset(list(val_table.index), valid_data_path, list(val_table.ground_truth)),\n",
    "                         batch_size=1, shuffle=False, num_workers=use_cpu)\n",
    "\n",
    "malconv = torch.load('checkpoint/example_sd_123.model', map_location=torch.device('cpu'))\n",
    "\n",
    "print(\"Loading MalConv model successful\")\n",
    "\n",
    "history = {}\n",
    "history['val_loss'] = []\n",
    "history['val_acc'] = []\n",
    "history['val_pred'] = []\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "total=0\n",
    "evade = 0\n",
    "changes=[]\n",
    "temp_df = pd.DataFrame(columns=['exe_input'])\n",
    "tensor_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3406: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "for _, val_batch_data in enumerate(validloader):\n",
    "    # total+=1\n",
    "    # print(total)\n",
    "    cur_batch_size = val_batch_data[0].size(0)\n",
    "    #print(\"cur batch size:\", cur_batch_size)\n",
    "\n",
    "    exe_input = val_batch_data[0].cuda() if use_gpu else val_batch_data[0]\n",
    "\n",
    "    data = exe_input[0].cpu().numpy()\n",
    "\n",
    "    length = data[-1]\n",
    "  \n",
    "    data = data[:length]\n",
    "    if length>2000000:\n",
    "        continue\n",
    "\n",
    "    # array_0 = np.full(2000000,0)\n",
    "    # array_1 = np.full(2000000,256)\n",
    "    # array_random = np.random.randint(0, 256, 2000000)\n",
    "\n",
    "    data = np.concatenate([data, np.random.randint(0, 256, 2000000 - length)])\n",
    "\n",
    "    init_prob = 0\n",
    " \n",
    "    label = val_batch_data[1].cuda() if use_gpu else val_batch_data[1]\n",
    " \n",
    "    label = Variable(label.float(), requires_grad=False)\n",
    "\n",
    "    label = Variable(torch.from_numpy(np.array([[0]])).float(), requires_grad=False)\n",
    "\n",
    "    embed = malconv.embed\n",
    "    sigmoid = nn.Sigmoid()\n",
    "    count_j = 0\n",
    "    t=0\n",
    "\n",
    "    exe_input = torch.from_numpy(np.array([data]))\n",
    "    exe_input = Variable(exe_input.long(), requires_grad=False)\n",
    "\n",
    "    exe_input = exe_input.to(dtype = torch.float32)\n",
    "    # pred = malconv(exe_input)\n",
    "    # prob = sigmoid(pred).cpu().data.numpy()[0][0]\n",
    " \n",
    "\n",
    "    # array_0_tensor = torch.from_numpy(np.array([array_0]))\n",
    "    # array_0_tensor = Variable(array_0_tensor.long(), requires_grad=False)\n",
    "\n",
    "    # array_1_tensor = torch.from_numpy(np.array([array_1]))\n",
    "    # array_1_tensor = Variable(array_1_tensor.long(), requires_grad=False)\n",
    "\n",
    "    # array_random_tensor = torch.from_numpy(np.array([array_random]))\n",
    "    # array_random_tensor = Variable(array_random_tensor.long(), requires_grad=False)\n",
    "    # temp_df = temp_df.append({'exe_input':exe_input}, ignore_index=True)\n",
    "\n",
    "    tensor_list.append(exe_input)\n",
    "    total += 1\n",
    "    if total>15:\n",
    "        sys.exit()\n",
    "    if total%10==0:\n",
    "        print(total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2000000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#print(tensor_list[0:1])\n",
    "background = torch.stack(tensor_list[0:10], dim = 0).squeeze(1)\n",
    "background.shape\n",
    "#explainer = shap.DeepExplainer(malconv, background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_numpy = background.cpu().numpy()\n",
    "background_list = [x.tolist() for x in background_numpy]\n",
    "#explainer = lime_tabular.LimeTabularExplainer(background_list)\n",
    "explainer = lime_tabular.LimeTabularExplainer(np.array(background_list), mode='classification')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = torch.stack(tensor_list[11:12], dim=0).squeeze(1)\n",
    "test_tensor_numpy = test_tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.9/site-packages/lime/lime_tabular.py:372: UserWarning: \n",
      "                    Prediction probabilties do not sum to 1, and\n",
      "                    thus does not constitute a probability space.\n",
      "                    Check that you classifier outputs probabilities\n",
      "                    (Not log probabilities, or actual class predictions).\n",
      "                    \n",
      "  warnings.warn(\"\"\"\n"
     ]
    }
   ],
   "source": [
    "#print(len(test_tensor_numpy[0]))\n",
    "# Explain the prediction for the test instance using LIME\n",
    "def predict_fn(inputs):\n",
    "    inputs = torch.from_numpy(inputs)\n",
    "    # Preprocess inputs if needed\n",
    "    outputs = malconv(inputs)  # Assuming malconv is your model\n",
    "    return outputs.detach().cpu().numpy()\n",
    "\n",
    "exp = explainer.explain_instance(test_tensor_numpy[0], predict_fn, labels=(0,), num_features=len(test_tensor_numpy[0]), num_samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_values = exp.as_list(label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lime_values)\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[:,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('output.csv', 'w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(lime_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('output.json', 'w') as json_file:\n",
    "    json.dump(lime_values, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_central_element(value):\n",
    "    # Split the value based on '<', '<=', '>', or '>='\n",
    "    parts = re.split(r'(<|<=|>|>=)', value)\n",
    "    \n",
    "    # Initialize variables to store integer and float parts\n",
    "    int_part = None\n",
    "    float_part = None\n",
    "    \n",
    "    # Loop through the parts and extract integer and float parts\n",
    "    for part in parts:\n",
    "        part = part.strip()\n",
    "        if part.isdigit():\n",
    "            int_part = int(part)\n",
    "        elif '.' in part:\n",
    "            try:\n",
    "                float_part = float(part)\n",
    "            except ValueError:\n",
    "                pass  # Ignore if unable to convert to float\n",
    "    \n",
    "    # Return the integer and float parts as a tuple\n",
    "    return int_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy[['IntegerElement']] = df_copy[df_copy.columns[0]].apply(lambda x: pd.Series(extract_central_element(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_copy.iloc[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df_copy.sort_values(by=df_copy.columns[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_sorted.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group the DataFrame into groups of 10,000 elements based on column 2\n",
    "# df_sorted[df_sorted.columns[2]] = df_sorted[df_sorted.columns[2]].astype(int)\n",
    "# df_sorted[df_sorted.columns[1]] = df_sorted[df_sorted.columns[1]].astype(float)\n",
    "\n",
    "df_sorted['Group'] = (df_sorted[df_sorted.columns[2]] // 50000)*50000\n",
    "\n",
    "# Calculate the sum of values in column 1 for each group\n",
    "result = df_sorted.groupby('Group')[df_sorted.columns[1]].sum()\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "result_df = pd.DataFrame({'Range': result.index, 'Sum of Column1': result.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['Sum of Column1'] = result_df['Sum of Column1'].apply(lambda x: '{:.7f}'.format(x))\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
